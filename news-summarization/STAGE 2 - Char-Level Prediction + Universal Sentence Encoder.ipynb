{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install seaborn\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, Bidirectional, Input, Embedding \n",
    "from tensorflow.keras.layers import Dropout, Conv1D, Flatten\n",
    "from tensorflow.keras.layers import Concatenate, Dot, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmpUE_ZxmGGC"
   },
   "outputs": [],
   "source": [
    "newsdf = pd.read_csv(\"./data/cleannewsdata.csv\")\n",
    "newsdf.Summary = newsdf.Summary.apply(lambda s: s[6:])\n",
    "def cleaner(s):\n",
    "    s = re.sub(\"[.?%$0-9!&*+-/:;<=\\[\\]Â£]\",\" \", s)\n",
    "    return \" \"+\" \".join(s.split())\n",
    "newsdf.Summary = newsdf.Summary.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrJ-iN-5uVG3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1616, 4), (403, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "testindices = np.random.choice(newsdf.shape[0], np.int(0.2*newsdf.shape[0]), replace=False)\n",
    "trainindices = np.sort(list(set(np.arange(newsdf.shape[0]))-set(testindices)))\n",
    "traindf, testdf = newsdf.iloc[trainindices], newsdf.iloc[testindices]\n",
    "traindf.shape, testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "680xgg673zeZ"
   },
   "outputs": [],
   "source": [
    "vocab = np.unique([word for sent in newsdf.Summary.apply(lambda s: list(s)).values for word in sent])\n",
    "def windowed_summary(s, WINDOW_LENGTH=100):\n",
    "    summ = np.zeros((len(s)-WINDOW_LENGTH, WINDOW_LENGTH))\n",
    "    nextchar = np.zeros(len(s)-WINDOW_LENGTH, dtype='<U1')\n",
    "    for i in range(WINDOW_LENGTH, len(s)):\n",
    "        summ[i-WINDOW_LENGTH,:] = [np.where(vocab==r)[0][0] for r in list(s[i-WINDOW_LENGTH:i])]\n",
    "        nextchar[i-WINDOW_LENGTH] = s[i]\n",
    "    return summ, nextchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWuv0uhroZu5"
   },
   "outputs": [],
   "source": [
    "def LSTM_data(df, WINDOW_LENGTH=100):\n",
    "    chararray = np.zeros((df.Summary.apply(lambda s: len(s)-WINDOW_LENGTH).sum(), WINDOW_LENGTH))\n",
    "    predarray = np.zeros((df.Summary.apply(lambda s: len(s)-WINDOW_LENGTH).sum(), vocab.shape[0]))\n",
    "    pos = 0\n",
    "    for i in range(df.shape[0]):\n",
    "    chars, nextval = windowed_summary(df.iloc[i]['Summary'])\n",
    "    chararray[pos:pos+chars.shape[0],:] = chars\n",
    "    for j in range(pos, pos+nextval.shape[0]):\n",
    "        predarray[j,np.where(vocab==nextval[j-pos])[0][0]] = 1\n",
    "    pos+=chars.shape[0]\n",
    "    return chararray, predarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYrJ12S-68fn"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "trainX, trainY = LSTM_data(traindf)\n",
    "testX, testY = LSTM_data(testdf)\n",
    "print(\"Data Generation Exited in \"+str(time.time()-start))\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymPrw2ml6KQH"
   },
   "outputs": [],
   "source": [
    "#Generate Universal Sentence Encodings\n",
    "trainstateX = embed(traindf.Text.values).numpy()\n",
    "trainstateX = np.repeat(trainstateX, traindf.Summary.apply(lambda s: len(s)-100).values, 0)\n",
    "teststateX = embed(testdf.Text.values).numpy()\n",
    "teststateX = np.repeat(teststateX, testdf.Summary.apply(lambda s: len(s)-100).values, 0)\n",
    "trainstateX.shape, teststateX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQhds8nhnfW0"
   },
   "outputs": [],
   "source": [
    "latentdim = 512\n",
    "tf.keras.backend.clear_session()\n",
    "state = Input(shape=(latentdim,))\n",
    "decinput = Input(shape=(100,))\n",
    "embed_layer = Embedding(vocab.shape[0], vocab.shape[0], weights=[np.eye(vocab.shape[0])], \n",
    "                           trainable=False, input_length=100)\n",
    "embedval = embed_layer(decinput)\n",
    "lstm_layer1 = LSTM(latentdim, return_sequences=True, return_state=True)\n",
    "lstm1val, _, _ = lstm_layer1(embedval, initial_state=[state, state])\n",
    "lstm1val = Dropout(0.175)(lstm1val)\n",
    "lstm_layer2 = Bidirectional(LSTM(latentdim, return_sequences=True, return_state=True))\n",
    "lstm2val, _, _, _, _ = lstm_layer2(lstm1val)\n",
    "lstm2val = Dropout(0.175)(lstm2val)\n",
    "lstm_layer3 = LSTM(latentdim, return_sequences=False, return_state=True)\n",
    "lstm3val, _, _ = lstm_layer3(lstm2val, initial_state=[state, state])\n",
    "lstm3val = Dropout(0.175)(lstm3val)\n",
    "dense_layer = Dense(vocab.shape[0], activation=\"softmax\")\n",
    "output = dense_layer(lstm3val)\n",
    "mdl = Model(inputs=[decinput, state], outputs=output)\n",
    "mdl.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpficEUUv2LB"
   },
   "outputs": [],
   "source": [
    "chckpt = tf.keras.callbacks.ModelCheckpoint(\"./data/newspred.h5\", monitor='val_loss', save_best_only=True,\n",
    "                                            save_weights_only=True, save_freq='epoch')\n",
    "hist = mdl.fit([trainX, trainstateX], trainY, callbacks=[chckpt], verbose=True, batch_size=1000, epochs=10,\n",
    "               validation_data=([testX, teststateX], testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.load_weights(\"./data/newspred.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPoCqKSIt_jK"
   },
   "outputs": [],
   "source": [
    "def generate_text(state, start):\n",
    "    start = start.reshape(1, start.shape[-1])\n",
    "    state = state.reshape(1, state.shape[-1])\n",
    "    print(\"\".join(char for char in start[0]))\n",
    "    for _ in range(1000):\n",
    "        pred = mdl.predict([start, state])\n",
    "        char = vocab[np.int(np.argmax(pred[0]))]\n",
    "        print(char)\n",
    "        start[0,:-1] = start[0,1:]\n",
    "        start[0,-1] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BT1FCWZbvD7z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ATTEMPT 2 - Char-Level Prediction + Universal Sentence Encoder",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
