{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook attempts to fit traditional NLP techniques - SVD, Trigrams etc. - to the economic data newspaper set to draw signal for the relevance dataset. To build robust trigram models, smoothening and discounting are used on the maximum likelihood statistics drawn to balance probability estimates for binary classification. The SVD attempts simple clustering mechanisms to find underlying similarities between article snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pickle.load(open('./data/relevance_trainX.pkl', \"rb\"))\n",
    "trainY = pickle.load(open('./data/relevance_trainY.pkl', \"rb\"))\n",
    "testX = pickle.load(open('./data/relevance_testX.pkl', \"rb\"))\n",
    "testY = pickle.load(open('./data/relevance_testY.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Supervised Learning - Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token cleaning: Stemming, <START> and <STOP>, <NUM> tag\n",
    "def num_tag(num):\n",
    "    digits = np.array(['1','2','3','4','5','6','7','8','9','0'])\n",
    "    return sum(np.vectorize(lambda s: s in num)(digits))>0\n",
    "def trigram_text(s):\n",
    "    s = \"<start> \"+s+\" <end>\"\n",
    "    return np.vectorize(lambda s: \"<num>\" if num_tag(s) else s)(s.split())\n",
    "trainX = trainX.apply(lambda txt: trigram_text(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating unigram, bigram and trigram probability dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing singular smoothing parameter through perplexity maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing train set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating test set probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Semi-Supervised Learning - SVD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
