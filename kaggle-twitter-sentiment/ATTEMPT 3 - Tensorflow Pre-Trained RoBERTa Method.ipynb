{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import re\n",
    "import pickle\n",
    "import gc\n",
    "import nltk\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "import matplotlib.pyplot as plt\n",
    "print('TF version',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")\n",
    "testdata = pd.read_csv(\"./data/test.csv\")\n",
    "data.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(sent):\n",
    "    #Two tokens (WEBSITE, VULGAR) are created and punctuation is spaced out\n",
    "    sent = \" \".join(np.vectorize(lambda s:\"WEBSITE\" if \"http\" in s else s)(np.array(sent.split())))\n",
    "    sent = re.sub(\"[!.?:;,`]\", \" \", sent)\n",
    "    return re.sub(re.compile('(?:\\*){2,}'),\"VULGAR\",sent).lower()\n",
    "for col in ['text','selected_text']:\n",
    "    data[col] = data[col].apply(lambda s: cleaner(s))\n",
    "testdata['text'] = testdata['text'].apply(lambda s: cleaner(s))\n",
    "data = data.loc[data.text.apply(lambda s: len(s))!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './tf-roberta/'\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=PATH+'vocab-roberta-base.json', \n",
    "    merges_file=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validitycheck(s):\n",
    "    target = s.selected_text.split()\n",
    "    source = s.text.split()\n",
    "    for i in range(len(source)):\n",
    "        if (source[i]==target[0]) and (source[i:i+len(target)]==target): return True\n",
    "    return False\n",
    "data = data.loc[data.apply(validitycheck, axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> N-Gram Level Subtext Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the observations established in ATTEMPT 2 regarding the similarity between \"text\" and \"selected_text\" for neutral sentiments which makes it favorable to merely predict the entire text (at 0.92 accuracy). For positive and negative labels, we attempt classifier and regressor designs to predict subtexts, or predict Jaccardian similarity with subtexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> STEP 1: Classifier </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(text):\n",
    "    ngrams, text = [], text.split()\n",
    "    for i in range(len(text)):\n",
    "        for j in range(i, len(text)):\n",
    "            ngrams.append(\" \".join(text[i:j+1]))\n",
    "    return np.array(ngrams)\n",
    "def Y(ngrams, selected_text):\n",
    "    return np.vectorize(lambda s: int(s==selected_text))(np.array(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = data.loc[data.sentiment==\"positive\", \"text\"].apply(lambda s: np.sum(np.arange(len(s.split())+1)))\n",
    "trainX = np.zeros(length.sum(), dtype=\"<U150\")\n",
    "trainY = np.zeros(length.sum(), dtype=np.float64)\n",
    "i=0\n",
    "for index, content in data.loc[data.sentiment==\"positive\"].iterrows():\n",
    "    ngrams = X(content.text)\n",
    "    trainX[i:i+len(ngrams)] = ngrams\n",
    "    trainY[i:i+len(ngrams)] =  Y(ngrams, content.selected_text)\n",
    "    i+=len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(trainY).plot(kind=\"hist\", bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Undersampling - Create a 5% Sampling Ratio\n",
    "majority, minority = np.where(trainY==0)[0], np.where(trainY==1)[0]\n",
    "kp = np.random.choice(majority, int(0.05*len(majority)), replace=False)\n",
    "trainX = trainX[np.sort(np.append(minority, kp))]\n",
    "trainY = trainY[np.sort(np.append(minority, kp))]\n",
    "pd.Series(trainY).plot(kind=\"hist\", bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Labels\n",
    "MAX_LEN = 100\n",
    "input_ids = np.ones((len(trainX),MAX_LEN),dtype='int32')\n",
    "attention_mask = np.zeros((len(trainX),MAX_LEN),dtype='int32')\n",
    "token_type_ids = np.zeros((len(trainX),MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(len(trainX)):\n",
    "    text1 = \" \"+\" \".join(trainX[k].split())\n",
    "    enc = tokenizer.encode(text1)\n",
    "    s_tok = sentiment_id[\"positive\"]\n",
    "    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask[k,:len(enc.ids)+5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word-Level BERT LSTM ANN\n",
    "def dense_mdl(nunits=100, recdrp=0.05, l2reg=0.05, drp=0.05):\n",
    "    input_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    attention_mask = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    token_type_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    x1 = tf.keras.layers.LSTM(nunits, recdrp=recdrp, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "                              bias_regularizer=tf.keras.regularizers.l2(l2reg), return_sequences=False)(x[0])\n",
    "    x1 = tf.keras.layers.Dropout(drp)(x1)\n",
    "    final = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x1)\n",
    "    model = tf.keras.models.Model([input_ids, attention_mask, token_type_ids], final)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss=\"binary_crossentropy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = dense_mdl()\n",
    "mdl.fit([input_ids, attention_mask, token_type_ids], trainY, epochs=10, batch_size=50, verbose=True,\n",
    "       class_weight={0:1, 1:pd.Series(trainY).value_counts()[0]/pd.Series(trainY).value_counts()[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>STEP 2: Regressor </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y(ngrams, subset):\n",
    "    def jaccard(str1, str2):\n",
    "        a, b = set(str1.lower().split()), set(str2.lower().split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    return np.vectorize(lambda s: jaccard(s, subset))(np.array(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence-Level BERT Dense ANN with Dual Input\n",
    "def dense_mdl(nunits=100, activation=\"relu\", l2reg=0.05, drp=0.05):\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    #Phrase analysis\n",
    "    input_ids1 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    attention_mask1 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    token_type_ids1 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    bert_model1 = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x1 = bert_model(input_ids1, attention_mask=attention_mask1, token_type_ids=token_type_ids1)\n",
    "    #Sentence analysis\n",
    "    input_ids2 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    attention_mask2 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    token_type_ids2 = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    bert_model2 = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x2 = bert_model2(input_ids2, attention_mask=attention_mask2, token_type_ids=token_type_ids2)\n",
    "    #Combined analysis\n",
    "    x = tf.concat([x1[1],x2[1]], axis=-1)\n",
    "    x = tf.keras.layers.Dense(nunits, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "                               bias_regularizer=tf.keras.regularizers.l2(l2reg))(x)\n",
    "    x = tf.keras.layers.Dropout(drp)(x)\n",
    "    final = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.models.Model([input_ids1, attention_mask1, token_type_ids1, input_ids2, \n",
    "                                   attention_mask2,token_type_ids2], final)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4), loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> HuggingFace Models </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start-Index and End-Index Dual TFRoberta Model\n",
    "def build_model(drp=0.10, l2reg=0.00, activation=None):\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
    "    x1 = tf.keras.layers.Dropout(drp)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(1,1, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "                               bias_regularizer=tf.keras.regularizers.l2(l2reg))(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    x2 = tf.keras.layers.Dropout(drp)(x[0])\n",
    "    x2 = tf.keras.layers.Conv1D(1,1, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "                               bias_regularizer=tf.keras.regularizers.l2(l2reg))(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small Addendum to leverage Token Classification for Individual Sentences\n",
    "bert_model = TFRobertaForTokenClassification.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "x = bert_model(ids,attention_mask=att,token_type_ids=tok, training=training)\n",
    "x1 = tf.keras.layers.Flatten()(x[0][:,:,-1])\n",
    "x1 = tf.keras.layers.Activation('softmax')(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
