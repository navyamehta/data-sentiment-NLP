{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The details of the Kaggle contest in question are at https://www.kaggle.com/c/tweet-sentiment-extraction/overview. In this notebook, we attempt to pre-process input datasets to prepare them for NLP modelling. Input tweet sequences are cleaned and tokenized, and then wrapped in a BERT embedding for contextual awareness. Output text sequences are merely tokenized on an external library given the need to preserve sentence phrases. A local BERT client is used to generate the datasets. To run BERT locally, <br\\><br/>\n",
    "<i>\n",
    "pip install bert-serving-server <br/>\n",
    "pip install bert-serving-client <br/>\n",
    "wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip && unzip uncased_L-12_H-768_A-12.zip\n",
    "<br/>\n",
    "bert-serving-start -model_dir uncased_L-12_H-768_A-12/ -num_worker=2 -max_seq_len 100\n",
    "</i>\n",
    "<p>\n",
    "    \n",
    "Since we know that the selected_text is a continuous textual segment, we attempt a different design architecture, where all possible n-grams of a text are evaluated to predict the sentiment, and the most likely n-gram is the one that most clearly encapsulates the sentiment in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from bert_serving.client import BertClient\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "import nltk.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/train.csv\")\n",
    "testdata = pd.read_csv(\"./data/test.csv\")\n",
    "data.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(sent):\n",
    "    #Two tokens (WEBSITE, VULGAR) are created and punctuation is spaced out\n",
    "    sent = \" \".join(np.vectorize(lambda s:\"WEBSITE\" if \"http\" in s else s)(np.array(sent.split())))\n",
    "    sent = re.sub(\"[!.?:;,`]\", \" \", sent)\n",
    "    return re.sub(re.compile('(?:\\*){2,}'),\"VULGAR\",sent).lower()\n",
    "for col in ['text','selected_text']:\n",
    "    data[col] = data[col].apply(lambda s: cleaner(s))\n",
    "testdata['text'] = testdata['text'].apply(lambda s: cleaner(s))\n",
    "data = data.loc[data.text.apply(lambda s: len(s))!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NEUTRAL SELECTION RATIO\n",
    "subset = data.loc[data.sentiment==\"neutral\", ['selected_text', 'text']].applymap(lambda s: len(s.split()))\n",
    "plt.hist(subset['selected_text']/subset['text'], bins=50, density=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our neutral label selection algorithm will be naive, passing the entire text as the selected_text since the approach holds for over 92% of input data. We shall now use all possible continuous n-grams from each input text and run a BERT embedding to build two separate models - positive side and negative side. For each side, the prediction quantity is the Jacardian similarity with the actual selected-text. For each tweet, the selected subtext will be the one with the highest predicted similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(text):\n",
    "    ngrams, text = [], text.split()\n",
    "    for i in range(len(text)):\n",
    "        for j in range(i, len(text)):\n",
    "            ngrams.append(\" \".join(text[i:j+1]))\n",
    "    return np.array(ngrams)\n",
    "def Y(ngrams, subset):\n",
    "    def jaccard(str1, str2):\n",
    "        a, b = set(str1.lower().split()), set(str2.lower().split())\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    return np.vectorize(lambda s: jaccard(s, subset))(np.array(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POSITIVE SENTIMENT\n",
    "sentdata = data.loc[data.sentiment==\"positive\", [\"text\", \"selected_text\"]].reset_index(drop=True)\n",
    "lengths = sentdata['text'].apply(lambda s: np.sum(np.arange(len(s.split())+1)))\n",
    "trainX = np.zeros((lengths.sum(),), dtype=np.dtype('U150'))\n",
    "trainY = np.zeros((lengths.sum(),), dtype=np.float64)\n",
    "i=0\n",
    "for index, content in sentdata.iterrows():\n",
    "    ngrams = X(content['text'])\n",
    "    trainX[i:i+len(ngrams)] = ngrams\n",
    "    trainY[i:i+len(ngrams)] = Y(ngrams, content['selected_text'])\n",
    "    i+=len(ngrams)\n",
    "#We shall run BERT Client in groups of 20,000 to not overwhelm limited computational resources\n",
    "group=20000\n",
    "bc = BertClient()\n",
    "for i in np.arange(0,len(trainX), group)[:2]:\n",
    "    bertX = bc.encode(list(trainX[i:i+group]))\n",
    "    pickle.dump(bertX, open(\"./data/positivetrainX/X\"+str(i)+\".pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
