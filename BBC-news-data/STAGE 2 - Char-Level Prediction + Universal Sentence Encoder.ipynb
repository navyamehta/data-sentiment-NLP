{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, Bidirectional, Input, Embedding \n",
    "from tensorflow.keras.layers import Dropout, Conv1D, Flatten\n",
    "from tensorflow.keras.layers import Concatenate, Dot, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmpUE_ZxmGGC"
   },
   "outputs": [],
   "source": [
    "newsdf = pd.read_csv(\"./cleannewsdata.csv\")\n",
    "newsdf.Summary = newsdf.Summary.apply(lambda s: s[6:])\n",
    "def cleaner(s):\n",
    "    s = re.sub(\"[.?%$0-9!&*+-/:;<=\\[\\]Â£]\",\" \", s)\n",
    "    return \" \"+\" \".join(s.split())\n",
    "newsdf.Summary = newsdf.Summary.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QrJ-iN-5uVG3",
    "outputId": "18a448ab-68ab-4f06-eef7-2b5d69f279e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1616, 4), (403, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "testindices = np.random.choice(newsdf.shape[0], np.int(0.2*newsdf.shape[0]), replace=False)\n",
    "trainindices = np.sort(list(set(np.arange(newsdf.shape[0]))-set(testindices)))\n",
    "traindf, testdf = newsdf.iloc[trainindices], newsdf.iloc[testindices]\n",
    "traindf.shape, testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "680xgg673zeZ"
   },
   "outputs": [],
   "source": [
    "vocab = np.unique([word for sent in newsdf.Summary.apply(lambda s: list(s)).values for word in sent])\n",
    "def windowed_summary(s, WINDOW_LENGTH=100):\n",
    "    summ = np.zeros((len(s)-WINDOW_LENGTH, WINDOW_LENGTH))\n",
    "    nextchar = np.zeros(len(s)-WINDOW_LENGTH, dtype='<U1')\n",
    "    for i in range(WINDOW_LENGTH, len(s)):\n",
    "        summ[i-WINDOW_LENGTH,:] = [np.where(vocab==r)[0][0] for r in list(s[i-WINDOW_LENGTH:i])]\n",
    "        nextchar[i-WINDOW_LENGTH] = s[i]\n",
    "    return summ, nextchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWuv0uhroZu5"
   },
   "outputs": [],
   "source": [
    "def LSTM_data(df, WINDOW_LENGTH=100):\n",
    "    chararray = np.zeros((df.Summary.apply(lambda s: len(s)-WINDOW_LENGTH).sum(), WINDOW_LENGTH))\n",
    "    predarray = np.zeros((df.Summary.apply(lambda s: len(s)-WINDOW_LENGTH).sum(), vocab.shape[0]))\n",
    "    pos = 0\n",
    "    for i in range(df.shape[0]):\n",
    "    chars, nextval = windowed_summary(df.iloc[i]['Summary'])\n",
    "    chararray[pos:pos+chars.shape[0],:] = chars\n",
    "    for j in range(pos, pos+nextval.shape[0]):\n",
    "        predarray[j,np.where(vocab==nextval[j-pos])[0][0]] = 1\n",
    "    pos+=chars.shape[0]\n",
    "    return chararray, predarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sYrJ12S-68fn",
    "outputId": "8dc34f4b-9122-4810-c282-995eb47fc352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generation Exited in 293.3199450969696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((907172, 100), (907172, 27), (225456, 100), (225456, 27))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "trainX, trainY = LSTM_data(traindf)\n",
    "testX, testY = LSTM_data(testdf)\n",
    "print(\"Data Generation Exited in \"+str(time.time()-start))\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ymPrw2ml6KQH",
    "outputId": "f31d432a-e919-408b-f243-20cdf91d2e24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((907172, 512), (225456, 512))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Universal Sentence Encodings\n",
    "trainstateX = embed(traindf.Text.values).numpy()\n",
    "trainstateX = np.repeat(trainstateX, traindf.Summary.apply(lambda s: len(s)-100).values, 0)\n",
    "teststateX = embed(testdf.Text.values).numpy()\n",
    "teststateX = np.repeat(teststateX, testdf.Summary.apply(lambda s: len(s)-100).values, 0)\n",
    "trainstateX.shape, teststateX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "rQhds8nhnfW0",
    "outputId": "69b346bc-8e8b-47b5-b360-b08a15484e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 27)      729         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100, 512), ( 1105920     embedding[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100, 512)     0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 100, 1024),  4198400     dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100, 1024)    0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512), (None, 3147776     dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 27)           13851       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,466,676\n",
      "Trainable params: 8,465,947\n",
      "Non-trainable params: 729\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latentdim = 512\n",
    "tf.keras.backend.clear_session()\n",
    "state = Input(shape=(latentdim,))\n",
    "decinput = Input(shape=(100,))\n",
    "embed_layer = Embedding(vocab.shape[0], vocab.shape[0], weights=[np.eye(vocab.shape[0])], \n",
    "                           trainable=False, input_length=100)\n",
    "embedval = embed_layer(decinput)\n",
    "lstm_layer1 = LSTM(latentdim, return_sequences=True, return_state=True)\n",
    "lstm1val, _, _ = lstm_layer1(embedval, initial_state=[state, state])\n",
    "lstm1val = Dropout(0.2)(lstm1val)\n",
    "lstm_layer2 = Bidirectional(LSTM(latentdim, return_sequences=True, return_state=True))\n",
    "lstm2val, _, _, _, _ = lstm_layer2(lstm1val, initial_state=[state, state, state, state])\n",
    "lstm2val = Dropout(0.2)(lstm2val)\n",
    "lstm_layer3 = LSTM(latentdim, return_sequences=False, return_state=True)\n",
    "lstm3val, _, _ = lstm_layer3(lstm2val, initial_state=[state, state])\n",
    "lstm3val = Dropout(0.2)(lstm3val)\n",
    "dense_layer = Dense(vocab.shape[0], activation=\"softmax\")\n",
    "output = dense_layer(lstm3val)\n",
    "mdl = Model(inputs=[decinput, state], outputs=output)\n",
    "mdl.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "lpficEUUv2LB",
    "outputId": "cf55796f-5433-4156-c005-e0c1ee9bf102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "908/908 [==============================] - 2787s 3s/step - loss: 2.1213 - val_loss: 1.6898\n",
      "Epoch 2/10\n",
      "908/908 [==============================] - 2782s 3s/step - loss: 1.5325 - val_loss: 1.4264\n",
      "Epoch 3/10\n",
      "908/908 [==============================] - 2784s 3s/step - loss: 1.3922 - val_loss: 1.3579\n",
      "Epoch 4/10\n",
      "908/908 [==============================] - 2783s 3s/step - loss: 1.3177 - val_loss: 1.3183\n",
      "Epoch 5/10\n",
      "908/908 [==============================] - 2783s 3s/step - loss: 1.2613 - val_loss: 1.2959\n",
      "Epoch 6/10\n",
      "908/908 [==============================] - 2787s 3s/step - loss: 1.2149 - val_loss: 1.2855\n",
      "Epoch 7/10\n",
      "908/908 [==============================] - 2798s 3s/step - loss: 1.1729 - val_loss: 1.2778\n",
      "Epoch 8/10\n",
      "908/908 [==============================] - 2787s 3s/step - loss: 1.1346 - val_loss: 1.2749\n",
      "Epoch 9/10\n",
      "908/908 [==============================] - 2790s 3s/step - loss: 1.0986 - val_loss: 1.2774\n",
      "Epoch 10/10\n",
      "908/908 [==============================] - 2791s 3s/step - loss: 1.0642 - val_loss: 1.2850\n"
     ]
    }
   ],
   "source": [
    "chckpt = tf.keras.callbacks.ModelCheckpoint(\"./newspred.h5\", monitor='val_loss', save_best_only=True,\n",
    "                                            save_weights_only=True, save_freq='epoch')\n",
    "hist = mdl.fit([trainX, trainstateX], trainY, callbacks=[chckpt], verbose=True, batch_size=1000, epochs=10,\n",
    "               validation_data=([testX, teststateX], testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A82LsnJVqd_e"
   },
   "outputs": [],
   "source": [
    "mdl.load_weights(\"./newspred.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KauMhuW0zCfQ"
   },
   "outputs": [],
   "source": [
    "def beamer(start, state, k, toplimit=10):\n",
    "    returnvals = collections.deque()\n",
    "    pred = mdl.predict([start, state])\n",
    "    if k==1:\n",
    "        returnvals.append(np.argmax(pred[0]))\n",
    "        return np.max(pred[0]), returnvals\n",
    "    else:\n",
    "        maxval, beamseq = None, None\n",
    "        topchoices = np.argsort(pred[0])[-toplimit:]\n",
    "        for j in topchoices:\n",
    "            chars = start.copy()\n",
    "            chars[0,:-1] = chars[0,1:]\n",
    "            chars[0,-1] = j\n",
    "            val, shortseq = beamer(chars, state, k-1)\n",
    "            if (not maxval) or ((val*pred[0,j])>maxval):\n",
    "                maxval = val*pred[0,j]\n",
    "                beamseq = shortseq\n",
    "                beamseq.appendleft(j)\n",
    "        return maxval, beamseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls1-4xFfr7uL"
   },
   "outputs": [],
   "source": [
    "def generate_text(start, state, k):\n",
    "    start = start.copy().reshape(1, start.shape[-1])\n",
    "    state = state.copy().reshape(1, state.shape[-1])\n",
    "    seq = \"\".join([vocab[np.int(char)] for char in start[0]])+\"|\"\n",
    "    for _ in range(200):\n",
    "        maxval, beamseq = beamer(start.copy(), state.copy(), k)\n",
    "        seq+=\"\".join([vocab[np.int(i)] for i in beamseq])\n",
    "        start[0,:-k] = start[0,k:]\n",
    "        start[0,-k:] = beamseq\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9mnR_EmT7FgK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ATTEMPT 2 - Char-Level Prediction + Universal Sentence Encoder",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
